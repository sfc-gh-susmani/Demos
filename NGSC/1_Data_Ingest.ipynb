{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "vcmifdgk5huzdgd5vtck",
   "authorId": "492945067848",
   "authorName": "SFACCHINE",
   "authorEmail": "saad.facchine@snowflake.com",
   "sessionId": "a12971e8-366e-4a76-be37-b305454a35ef",
   "lastEditTime": 1742411474112
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "9c4ba4ff-9ddc-4d5d-a96b-e4e2ff984ed2",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "/*----------------------------------------------------------------------------------\nStep 1 - Data Ingestion\n As a Tasty Bytes Data Engineer, we will now leverage the newly permissioned stage\n and file formats to ingest and transform our Truck POS data.\n \n Our in-truck POS systems create two seperate files (order_header and order_detail)\n for each order that is processed. Since our foundational order_id's are generated\n in the order_header files let's prioritize ingesting our header data first.\n----------------------------------------------------------------------------------*/\n\n--USE CASE 16: RBAC\n    \nCREATE ROLE IF NOT EXISTS tasty_data_engineer\n    COMMENT = 'data engineer for tasty bytes';\n\n--role heirarchy      \nGRANT ROLE tasty_data_engineer TO ROLE tasty_admin;\n\n--examples of privileges given to roles\nGRANT USAGE ON DATABASE frostbyte_tasty_bytes TO ROLE tasty_data_engineer;\nGRANT USAGE ON ALL SCHEMAS IN DATABASE frostbyte_tasty_bytes TO ROLE tasty_data_engineer;\nGRANT ALL ON WAREHOUSE tasty_de_wh TO ROLE tasty_data_engineer;\n\n--privileges can also be granted directly to users\nGRANT USAGE ON DATABASE frostbyte_tasty_bytes TO USER sfacchine;\n\n\n\n\n-- to begin, let's once again use the Data Engineer role and warehouse\nUSE ROLE tasty_data_engineer;\nUSE WAREHOUSE tasty_de_wh;\n\n-- with our context in place, let's now run a list command now filtering on the CSV Order Header directory\nLIST @frostbyte_tasty_bytes.public.s3load/raw_pos/order_header/;\n    --> demo tip: point out that the order_header data is partitioned by truck_id which is something we will address later.\n\n\n\n\n-- we have seen the files on the stage, let's now use our CSV file format and\n-- query the first 100 rows returned from the order_header files\nSELECT $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16\nFROM @frostbyte_tasty_bytes.public.s3load/raw_pos/order_header/\n    (FILE_FORMAT => frostbyte_tasty_bytes.public.csv_ff) \nLIMIT 100;\n\n\n-- uh oh! there are header rows, let's adjust our file format to handle these before moving on\nALTER FILE FORMAT frostbyte_tasty_bytes.public.csv_ff SET skip_header = 1;\n\n\n-- now let's create our table DDL \nUSE ROLE sysadmin;\n\n--USE CASE 5: Enabling CDC\nCREATE OR REPLACE TABLE frostbyte_tasty_bytes.raw_pos.order_header_demo\n(\n    order_id NUMBER(38,0),\n    truck_id NUMBER(38,0),\n    location_id FLOAT,\n    customer_id NUMBER(38,0),\n    discount_id VARCHAR(16777216),\n    shift_id NUMBER(38,0),\n    shift_start_time TIME(9),\n    shift_end_time TIME(9),\n    order_channel VARCHAR(16777216),\n    order_ts TIMESTAMP_NTZ(9),\n    served_ts VARCHAR(16777216),\n    order_currency VARCHAR(3),\n    order_amount NUMBER(38,4),\n    order_tax_amount VARCHAR(16777216),\n    order_discount_amount VARCHAR(16777216),\n    order_total NUMBER(38,4)\n)\nCHANGE_TRACKING = TRUE;\n\n\n-- with the table in place, we are now ready to load our data but first let's make sure we\n-- are using our Data Engineering Warehouse.\nUSE ROLE tasty_data_engineer;\nUSE WAREHOUSE tasty_de_wh;\n\n-- USE CASE 7: With the power of Snowflakes instant elasticity available, let's scale our warehouse up to 2XL\nALTER WAREHOUSE tasty_de_wh SET warehouse_size = '2x-large';\n\n-- now that our warehouse is scaled, let's kick off our COPY INTO script which will\n-- ingest our data from the stage into the table we just created.\nCOPY INTO frostbyte_tasty_bytes.raw_pos.order_header_demo\nFROM @frostbyte_tasty_bytes.public.s3load/raw_pos/order_header/\n    FILE_FORMAT = \n        (\n            FORMAT_NAME = 'frostbyte_tasty_bytes.public.csv_ff'\n            -- SKIP_HEADER = 1 -- this was addressed in our file format update so we won't need it!\n        );\n        \n-- with the load complete, let's scale our warehouse back down for now\nALTER WAREHOUSE tasty_de_wh SET warehouse_size = 'xsmall';\n\nselect count(*) from frostbyte_tasty_bytes.raw_pos.order_header_demo;\nselect * from frostbyte_tasty_bytes.raw_pos.order_header_demo limit 10;\n\n-- using our newly loaded table, let's see how many total orders, trucks and locations we ingested data for\nSELECT \n    COUNT(DISTINCT oh.order_id) AS count_orders,\n    COUNT(DISTINCT oh.truck_id) AS count_trucks,\n    COUNT(DISTINCT oh.location_id) AS count_locations\nFROM frostbyte_tasty_bytes.raw_pos.order_header_demo oh;\n\n\n--Change tracking\nSET ts1 = (SELECT CURRENT_TIMESTAMP());\n\n -- Insert new records with dates from the past week\nINSERT INTO ORDER_HEADER_DEMO (\n    ORDER_ID, TRUCK_ID, LOCATION_ID, CUSTOMER_ID, DISCOUNT_ID, SHIFT_ID, \n    SHIFT_START_TIME, SHIFT_END_TIME, ORDER_CHANNEL, ORDER_TS, SERVED_TS, \n    ORDER_CURRENCY, ORDER_AMOUNT, ORDER_TAX_AMOUNT, ORDER_DISCOUNT_AMOUNT, ORDER_TOTAL\n)\nVALUES\n(1, 1001, 501, 3001, 201, 401, '08:00:00', '16:00:00', 'Online', '2025-03-07 08:30:00', NULL, 'USD', 100.00, 5.00, 10.00, 95.00),\n(2, 1002, 502, 3002, 202, 402, '09:00:00', '17:00:00', 'In-Person', '2025-03-09 09:15:00', NULL, 'USD', 150.00, 7.50, 15.00, 142.50),\n(3, 1003, 503, 3003, 203, 403, '10:00:00', '18:00:00', 'App', '2025-03-11 10:45:00', NULL, 'USD', 200.00, 10.00, 20.00, 190.00);\n\n-- Delete a record\nDELETE FROM ORDER_HEADER_DEMO WHERE ORDER_ID = 1;\n\n-- Update a record\nUPDATE ORDER_HEADER_DEMO\nSET ORDER_AMOUNT = 175.00, ORDER_TOTAL = 167.50 \nWHERE ORDER_ID = 2;\n\n\n -- Query the change tracking metadata in the table during the interval from $ts1 to the current time.\n -- Return the full delta of the changes.\nSELECT *\n FROM order_header_demo\n   CHANGES(INFORMATION => DEFAULT)\n   AT(TIMESTAMP => $ts1);\n\nSELECT *\n FROM order_header_demo\n   CHANGES(INFORMATION => APPEND_ONLY)\n   AT(TIMESTAMP => $ts1);\n\n",
   "execution_count": null
  }
 ]
}